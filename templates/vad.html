<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
      .flex-container {
        display: flex;
        align-items: center; /* You can use 'baseline' if you prefer */
        gap: 1rem;           /* Adds some space between the button and paragraph */
      }
      p {
        margin: 0;           /* Remove default paragraph margin */
      }
    </style>
</head>
<body>
  <div class="flex-container">
    <button id="record" style="width: 70px; height: 25px;">
      Start
    </button>
    <button id="stop" style="width: 70px; height: 25px;">
      Stop
    </button>
    <p id="status"></p>
  </div>
    
    <p id="insert"> </p>
    

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
    <script>
      // === Configuration Constants ===
      const PRE_BUFFER_FRAME_COUNT = 8;  // Maintain the last 8 frames as pre-buffer.
      const TARGET_FRAME_COUNT    = 31;   // Send a chunk once we accumulate 31 frames.
    
      // === Global Variables ===
      let myvad;                         // The VAD instance.
      let framecounter = 0;
      const insert = document.getElementById('insert')

      // Use a single buffer for both pre-buffering and accumulating active speech frames.
      let activeBuffer = [];
      // Global flag indicating whether we're in an active speech segment.
      let speechActive = false;
    
      // Utility function to concatenate an array of Float32Arrays into one Float32Array.
      function concatFrames(frames) {
        const totalLength = frames.reduce((sum, frame) => sum + frame.length, 0);
        const result = new Float32Array(totalLength);
        let offset = 0;
        frames.forEach(frame => {
          result.set(frame, offset);
          offset += frame.length;
        });
        return result;
      }
    
      // === onFrameProcessed Callback ===
      function handleFrameProcessed(probabilities, frame) {
        if (!speechActive) {
          // When not in speech, append the incoming frame and keep only the last PRE_BUFFER_FRAME_COUNT frames.
          activeBuffer.push(frame);
          if (activeBuffer.length > PRE_BUFFER_FRAME_COUNT) {
            activeBuffer.shift();  // Remove the oldest frame.
          }
          // console.log("Idle frame inserted", framecounter, ":", probabilities);
          framecounter++;
        } else {
          // When speech is active, append every incoming frame to activeBuffer.
          activeBuffer.push(frame);
          // console.log("Speech frame inserted", framecounter, ":", probabilities);
          framecounter++;
    
          // Once we've accumulated TARGET_FRAME_COUNT frames, send them.
          if (activeBuffer.length >= TARGET_FRAME_COUNT) {
            const chunkToSend = concatFrames(activeBuffer);
            sockets[0].send(chunkToSend.buffer);
            console.log("Sent chunk of", activeBuffer.length, "frames.");
    
            // After sending, keep only the last PRE_BUFFER_FRAME_COUNT frames
            activeBuffer = []
          }
        }
      }
    
      // === onSpeechStart Callback ===
      function handleSpeechStart() {
        console.log("Speech Start detected.");
        speechActive = true;
        // No need to reinitialize activeBuffer here since it already holds the pre-buffer frames.
      }
    
      // === onSpeechEnd Callback ===
      function handleSpeechEnd(audio) {
        console.log("Speech End detected.");
        speechActive = false;
    
        // If there are any frames left in activeBuffer, send them as the final chunk.
        if (activeBuffer.length > 0) {
          const finalChunk = concatFrames(activeBuffer);
          sockets[0].send(finalChunk.buffer);
          console.log("Sent remaining chunk of", finalChunk.length, "samples.");
        }
    
        // Update activeBuffer to keep the last PRE_BUFFER_FRAME_COUNT frames for the next speech segment. 
        // This causes repetition. How?
        // if we have a speechStart event very close to a SpeechEnd event then the section sliced here will be sent twice. 
        // For example if a speech end is detected on merhaba bu (END) and after 3 frames, we have (START) the next frame to be sent will start from bu again. 
        // This start from bu should not happen. 
        // Why did we implement this in the first place?
        // if activeBuffer is completely empty this should not be a problem. lets assume we instantly get speechStart after speech end. 
        // in that case if there is pre speech, it is most likely in the previous frame already. 
        // or we get 1 frame of no speech and then speech Start. Which should be fine too as it will almost be continuous now. 
        // We do not need to save prepend buffer like this 
        // activeBuffer = activeBuffer.slice(-PRE_BUFFER_FRAME_COUNT);
        activeBuffer = []
      }
      // // Default V5 ProcessorOptions
      // export const defaultV5FrameProcessorOptions: FrameProcessorOptions = {
      //   positiveSpeechThreshold: 0.5, // Thresholds may greatly vary depending on the environment its being used. 0.5 is good for a decently high volume mic input.
      //   negativeSpeechThreshold: 0.5 - 0.15,
      //   preSpeechPadFrames: 3, // This does not matter (since we do preSpeechPadding ourselves. )
      //   redemptionFrames: 24, // This can be changed to 16.
      //   frameSamples: 512,
      //   minSpeechFrames: 9, // This can be lowered for better single word detection. (But also does not matter since we treat VADMisfire Same as SpeechEnd)
      //   submitUserSpeechOnPause: false,
      // }
      // === VAD Instance Creation & Starting ===
      async function main() {
        myvad = await vad.MicVAD.new({
          model: "v5",
          frameSamples: 512,
          redemptionFrames: 16,
          threshold: 0.4,
          onSpeechStart: handleSpeechStart,
          onSpeechEnd: handleSpeechEnd,
          onVADMisfire: handleSpeechEnd,
          onFrameProcessed: handleFrameProcessed
        });
        myvad.start();
      }
    
      // === Button Control Logic ===
      const record_button = document.getElementById('record');
      const stop_button = document.getElementById('stop')
      const status = document.getElementById('status')
      let isFirstClick = true;
      let sockets = []
      record_button.onclick = () => {
        if (isFirstClick) {
          // Initialize websocket after user clicks record. 
          
          status.textContent = "Initializing"
        
          const socket = new WebSocket('ws://127.0.0.1:5004/save');

          socket.onerror = (event) => {
            status.textContent = "Could not connect"
            record_button.textContent = "Start"
            isFirstClick = true
          }

          socket.onopen = (event) => {
            console.log("selam")
            sockets.push(socket) // Push the newly created websocket to the array so it can be accessed globally.
            socket.onmessage = (event) => { // Initialize the on message event
            insert.textContent = event.data
            }
            main()
            .then(() => {
              // Once VAD is created and started:
              isFirstClick = false;
              status.textContent = "Start Speaking";
              record_button.textContent = "Pause";
            })
            .catch((error) => {
              console.error("Error starting VAD:", error);
            });
          }

        } else if (myvad.listening) {
          console.log(myvad.spee)
          if (speechActive) {
            handleSpeechEnd()
          } // Pause triggers onSpeechEnd() so we do not lose any audio when we pause. only if while speech is active
          myvad.pause();
          sockets[0].send("Pause");
          status.textContent = "Paused."
          record_button.textContent = "Continue";
        } else if (!myvad.listening) {
          myvad.start();
          status.textContent = "Speak"
          record_button.textContent = "Pause";
        }
      };

      stop_button.onclick = () => {
        sockets[0].send("Stop")
        sockets[0].onerror = null // remove event handlers so that 
        sockets.pop()
        
        status.textContent = "Stopped Session, press start for a new session."
        myvad.pause()
        record_button.textContent = "Start"
        isFirstClick = true

      }


    </script>
    
</body>
</html>

