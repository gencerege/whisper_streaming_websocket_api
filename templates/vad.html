<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
      .flex-container {
        display: flex;
        align-items: center; /* You can use 'baseline' if you prefer */
        gap: 1rem;           /* Adds some space between the button and paragraph */
      }
      p {
        margin: 0;           /* Remove default paragraph margin */
      }
    </style>
</head>
<body>
  <div class="flex-container">
    <button id="record" style="width: 70px; height: 25px;">
      Start
    </button>
    <button id="stop" style="width: 70px; height: 25px;">
      Stop
    </button>
    <p id="status"></p>
  </div>
    
    <p id="insert"> </p>
    

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
    <script>

      // Utility function to concatenate an array of Float32Arrays into one Float32Array.
      function concatFrames(frames) {
        const totalLength = frames.reduce((sum, frame) => sum + frame.length, 0);
        const result = new Float32Array(totalLength);
        let offset = 0;
        frames.forEach(frame => {
          result.set(frame, offset);
          offset += frame.length;
        });
        return result;
      }

      // === Configuration Constants ===
      const PRE_BUFFER_FRAME_COUNT = 8;  // Maintain the last 8 frames as pre-buffer.
      const TARGET_FRAME_COUNT    = 32;   // Send a chunk once we accumulate 31 frames.
    
      // Edge Cases
        // #1 What happens if first frame has probabilities.isSpeech = true
        // 

      // === Global Variables ===
      let myvad                         // The VAD instance.
      
      const insert = document.getElementById('insert')
      
      // Use a single buffer for both pre-buffering and accumulating active speech frames.
      let activeBuffer = [];
      let frameCount = 0
      // Global flag indicating whether we're in an active speech segment.
      let speechActive = false;
      let speechPadFrames = 8;
      let redemptionFrames = 0
      let sentRedemptionFrames = 0
      let threshold = 0.4
  
    
    
      // === onFrameProcessed Callback ===
      function handleFrameProcessed(probabilities, frame) {
        if (!speechActive && probabilities.isSpeech >= threshold) {
          console.log("Frame: ", frameCount, "Speech Prob: ", probabilities.isSpeech, "speechActive: ", speechActive, "typeOfFrame: start")

        } else if (!speechActive) {
          console.log("Frame: ", frameCount, "Speech Prob: ", probabilities.isSpeech, "speechActive: ", speechActive, "typeOfFrame: noSpeech")
        }

        if (speechActive && probabilities.isSpeech >= threshold) {
          console.log("Frame: ", frameCount, "Speech Prob: ", probabilities.isSpeech, "speechActive: ", speechActive, "typeOfFrame: speech")
        } else if (speechActive && probabilities.isSpeech < threshold - 0.15) {
          console.log("Frame: ", frameCount, "Speech Prob: ", probabilities.isSpeech, "speechActive: ", speechActive, "typeOfFrame: redemption")
        } else if (speechActive) {
          console.log("Frame: ", frameCount, "Speech Prob: ", probabilities.isSpeech, "speechActive: ", speechActive, "typeOfFrame: neutral")
        }


        
        activeBuffer.push(frame)
        frameCount ++

        if (probabilities.isSpeech >= threshold && redemptionFrames != 0) {
          redemptionFrames = 0
          sentRedemptionFrames = 0 // If we have sent redemption frames previously, these are not redemption frames anymore. They are silence frames. 
        }

        if (speechActive && probabilities.isSpeech < threshold - 0.15) {
          redemptionFrames++
        }

        if (redemptionFrames >= 16) {
          speechActive = false
          speechEndAtFrame = frameCount
          console.log("Speech End Detected")
          if (sentRedemptionFrames == 0) {
            speechEndIndex = speechEndAtFrame - speechPadFrames // If speech ends at 30th frame and we have 8 padFrames
                                                                // First frame with isSpeech < threshold is redemptionFrame #1. The Frame before that is the lastSpeechFrame. 
                                                                // lastSpeechFrame is the 14th frame if there is 16 redemptionFrames. [15-30]
                                                                // when we pad 8 frames to the 14th frame we have frames [14-22] (9 frames in total)
                                                                // frame 22 is indexed 21 and 30 - 8 is 22. We would -1 like we would on speechStartIndex, but the end index is not included
                                                                // when we slice(start, 22) included frames are [start, 21]. assuming start = 0 (1st frame) there are 22 frames as there should. 
            framesToSend = activeBuffer.slice(speechStartIndex, speechEndIndex)                                                  
            sockets[0].send(concatFrames(framesToSend))
            console.log("No previously sent redemption frames. Sending ", speechStartIndex, " to ", speechEndIndex - 1)
          } else if (sentRedemptionFrames > 0) {
            speechEndIndex = speechStartIndex + speechPadFrames - sentRedemptionFrames
            framesToSend = activeBuffer.slice(speechStartIndex, speechEndIndex)
            console.log("Previously sent redemption frames: ", sentRedemptionFrames)
            
            if (framesToSend.length > 0)
              console.log("Sending redemption frames: ", speechStartIndex, " to ", speechEndIndex - 1, " as padding")
            sockets[0].send(concatFrames(framesToSend)) 
          }

          speechStartIndex = 2500000000000000 // Temporary solution
          redemptionFrames = 0
          sentRedemptionFrames = 0
        }           

        if (probabilities.isSpeech >= 0.4 && !speechActive) {
          console.log("Speech Start")
          speechActive = true
          speechStartAtFrame = frameCount
          speechStartIndex = frameCount - speechPadFrames - 1 // If 20th frame is the first speech positive frame, and we pad by 8 Frames. We need 9 frames [12, 20]
                                                                // In the activeBuffer 20th frame has index 19, 12th Frame has index 11. So we have a - 1
                                                                // We can add an if statement for Edge Case #1
        }
        // If speech start at frame 32 (padding included) and currently we have 55 frames in the buffer.
        // including frame32 55-32+1 frames. frameCount - start + 1. 
        if (speechActive) {
          if (frameCount - speechStartIndex >= TARGET_FRAME_COUNT && redemptionFrames <= speechPadFrames) {
            framesToSend = activeBuffer.slice(speechStartIndex, frameCount)
            sockets[0].send(concatFrames(framesToSend)) // This will send TARGET_FRAME_COUNT amount of frames, only if redemption frames 
            console.log("sent 1 second of audio: ", framesToSend.length, " frames from: ", speechStartIndex, " to ", frameCount - 1, " speech start moved to: ", frameCount)
            speechStartIndex = frameCount // move the speechStartIndex to the next frame.
            sentRedemptionFrames = redemptionFrames
          }
        }
      }
    
      // // === onSpeechStart Callback ===
      // function handleSpeechStart() {
      //   console.log("Speech Start detected.");
      //   speechActive = true;
      //   // No need to reinitialize activeBuffer here since it already holds the pre-buffer frames.
      // }
    
      // // === onSpeechEnd Callback ===
      // function handleSpeechEnd(audio) {
      //   console.log("Speech End detected.");
      //   speechActive = false;
    
      //   // If there are any frames left in activeBuffer, send them as the final chunk.
      //   if (activeBuffer.length > 0) {
      //     const finalChunk = concatFrames(activeBuffer);
      //     sockets[0].send(finalChunk.buffer);
      //     console.log("Sent remaining chunk of", finalChunk.length, "samples.");
      //   }
    
        // Update activeBuffer to keep the last PRE_BUFFER_FRAME_COUNT frames for the next speech segment. 
        // This causes repetition. How?
        // if we have a speechStart event very close to a SpeechEnd event then the section sliced here will be sent twice. 
        // For example if a speech end is detected on merhaba bu (END) and after 3 frames, we have (START) the next frame to be sent will start from bu again. 
        // This start from bu should not happen. 
        // Why did we implement this in the first place?
        // if activeBuffer is completely empty this should not be a problem. lets assume we instantly get speechStart after speech end. 
        // in that case if there is pre speech, it is most likely in the previous frame already. 
        // or we get 1 frame of no speech and then speech Start. Which should be fine too as it will almost be continuous now. 
        // We do not need to save prepend buffer like this 
      //   // activeBuffer = activeBuffer.slice(-PRE_BUFFER_FRAME_COUNT);
      //   activeBuffer = []
      // }
      // // Default V5 ProcessorOptions
      // export const defaultV5FrameProcessorOptions: FrameProcessorOptions = {
      //   positiveSpeechThreshold: 0.5, // Thresholds may greatly vary depending on the environment its being used. 0.5 is good for a decently high volume mic input.
      //   negativeSpeechThreshold: 0.5 - 0.15,
      //   preSpeechPadFrames: 3, // This does not matter (since we do preSpeechPadding ourselves. )
      //   redemptionFrames: 24, // This can be changed to 16.
      //   frameSamples: 512,
      //   minSpeechFrames: 9, // This can be lowered for better single word detection. (But also does not matter since we treat VADMisfire Same as SpeechEnd)
      //   submitUserSpeechOnPause: false,
      // }
      // === VAD Instance Creation & Starting ===
      async function main() {
        myvad = await vad.MicVAD.new({
          model: "v5",
          frameSamples: 512,
          redemptionFrames: 16,
          positiveSpeechThreshold: 0.4,
          negativeSpeechThreshold: 0.4 - 0.15,
          // onSpeechStart: handleSpeechStart,
          // onSpeechEnd: handleSpeechEnd,
          // onVADMisfire: handleSpeechEnd,
          onFrameProcessed: handleFrameProcessed
        });
        myvad.start();
      }
    
      // === Button Control Logic ===
      const record_button = document.getElementById('record');
      const stop_button = document.getElementById('stop')
      const status = document.getElementById('status')
      let isFirstClick = true;
      let sockets = []
      record_button.onclick = () => {
        if (isFirstClick) {
          // Initialize websocket after user clicks record. 
          
          status.textContent = "Initializing"
        
          const socket = new WebSocket('ws://127.0.0.1:5004/save');

          socket.onerror = (event) => {
            status.textContent = "Could not connect"
            record_button.textContent = "Start"
            isFirstClick = true
          }

          socket.onopen = (event) => {
            console.log("selam")
            sockets.push(socket) // Push the newly created websocket to the array so it can be accessed globally.
            socket.onmessage = (event) => { // Initialize the on message event
            insert.textContent = event.data
            }
            main()
            .then(() => {
              // Once VAD is created and started:
              isFirstClick = false;
              status.textContent = "Start Speaking";
              record_button.textContent = "Pause";
            })
            .catch((error) => {
              console.error("Error starting VAD:", error);
            });
          }

        } else if (myvad.listening) {
          if (speechActive) {
            handleSpeechEnd()
          } // Pause triggers onSpeechEnd() so we do not lose any audio when we pause. only if while speech is active
          myvad.pause();
          sockets[0].send("Pause");
          status.textContent = "Paused."
          record_button.textContent = "Continue";
        } else if (!myvad.listening) {
          myvad.start();
          status.textContent = "Speak"
          record_button.textContent = "Pause";
        }
      };

      stop_button.onclick = () => {
        sockets[0].send("Stop")
        sockets[0].onerror = null // remove event handlers so that 
        sockets.pop()
        
        status.textContent = "Stopped Session, press start for a new session."
        myvad.pause()
        record_button.textContent = "Start"
        isFirstClick = true

      }


    </script>
    
</body>
</html>

